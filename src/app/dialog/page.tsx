'use client'

import { FormEvent, useEffect, useMemo, useRef, useState } from 'react'
import Link from 'next/link'
import { AuthGuard } from '@/components/auth-guard'
import { useLanguage } from '@/contexts/language-context'
import { translations, type Language } from '@/locales'
import { motion, AnimatePresence } from 'framer-motion'
import { cn } from '@/lib/utils'

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤ Azure –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞
const VOICE_CONFIG: Record<Language, { voice: string; xmlLang: string; speechRecognitionLang: string }> = {
  ru: {
    voice: 'ru-RU-SvetlanaNeural',
    xmlLang: 'ru-RU',
    speechRecognitionLang: 'ru-RU'
  },
  kk: {
    voice: 'kk-KZ-AigulNeural',
    xmlLang: 'kk-KZ',
    speechRecognitionLang: 'kk-KZ'
  },
  en: {
    voice: 'en-US-AriaNeural',
    xmlLang: 'en-US',
    speechRecognitionLang: 'en-US'
  }
}

interface ChatMessage {
  id: string
  role: 'user' | 'assistant'
  text: string
  actions?: Array<{
    label: string
    href: string
  }>
  meta?: {
    meetingId?: string
    meetingCode?: string
    questionId?: string
    questionNumber?: number
  }
}

interface ChatApiResponse {
  success: boolean
  message?: {
    text: string
    actions?: ChatMessage['actions']
    meta?: ChatMessage['meta']
  }
  error?: string
}
interface MeetingListItem {
  id: string
  code: string
  titleRu: string
  titleKk: string
  titleEn: string
  questions: Array<{
    id: string
    number: number
    titleRu: string
    titleKk: string
    titleEn: string
  }>
}

export default function DialogPage() {
  const { language } = useLanguage()
  const tDialog = translations[language].dialog
  const [inputValue, setInputValue] = useState('')
  const [messages, setMessages] = useState<ChatMessage[]>([])
  const [isThinking, setIsThinking] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [isTranscribing, setIsTranscribing] = useState(false)
  const [playingAudioId, setPlayingAudioId] = useState<string | null>(null)
  const [loadingAudioId, setLoadingAudioId] = useState<string | null>(null)
  const [meetings, setMeetings] = useState<MeetingListItem[]>([])
  const messagesEndRef = useRef<HTMLDivElement | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const audioRef = useRef<HTMLAudioElement | null>(null)
  
  // Azure Speech Recognition states (–¥–ª—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞)
  const [isAvatarInitialized, setIsAvatarInitialized] = useState(false)
  const [azureConfig, setAzureConfig] = useState<{key: string, region: string} | null>(null)
  const videoRef = useRef<HTMLVideoElement>(null)
  const speechRecognizerRef = useRef<any>(null)

  useEffect(() => {
    const loadMeetings = async () => {
      try {
        const response = await fetch('/api/dialog/meetings')
        if (!response.ok) {
          throw new Error('Failed to load meetings')
        }
        const data = await response.json()
        if (data.success) {
          setMeetings(data.meetings)
        }
      } catch (error) {
        console.error('[Dialog] Failed to fetch meetings:', error)
      }
    }

    loadMeetings()
  }, [])

  // –ó–∞–≥—Ä—É–∑–∫–∞ Azure –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞
  useEffect(() => {
    fetch('/api/azure-speech-config')
      .then(res => res.json())
      .then(config => {
        setAzureConfig(config)
        console.log('‚úÖ Azure config loaded for avatar')
      })
      .catch(err => {
        console.error('‚ùå Failed to load Azure config:', err)
      })
  }, [])

  // –ó–∞–≥—Ä—É–∑–∫–∞ Azure Speech SDK –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞
  useEffect(() => {
    const script = document.createElement('script')
    script.src = 'https://aka.ms/csspeech/jsbrowserpackageraw'
    script.async = true
    script.onload = () => {
      console.log('‚úÖ Azure Speech SDK loaded')
      setIsAvatarInitialized(true)
    }
    script.onerror = () => {
      console.error('‚ùå Failed to load Azure Speech SDK')
    }
    document.body.appendChild(script)

    return () => {
      if (speechRecognizerRef.current) {
        speechRecognizerRef.current.close()
      }
    }
  }, [])

  const suggestions = useMemo(() => {
    if (meetings.length === 0) {
      return []
    }

    const meeting = meetings[0]
    const localizedTitle = selectTitle(meeting, language)
    return meeting.questions.slice(0, 3).map((question) => {
      return formatSuggestion(language, meeting.code, question.number, selectQuestionTitle(question, language) || localizedTitle)
    })
  }, [meetings, language])

  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [messages])

  // Azure Speech Recognition –¥–ª—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  const startAzureSpeechRecognition = async () => {
    if (!isAvatarInitialized || !azureConfig) {
      alert('–ê–≤–∞—Ç–∞—Ä –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∞–≤–∞—Ç–∞—Ä.')
      return
    }

    const SpeechSDK = (window as any).SpeechSDK
    
    try {
      setIsRecording(true)
      setIsTranscribing(false)

      const voiceConfig = VOICE_CONFIG[language]
      const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(azureConfig.key, azureConfig.region)
      speechConfig.speechRecognitionLanguage = voiceConfig.speechRecognitionLang
      
      const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput()
      const recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig)
      speechRecognizerRef.current = recognizer

      recognizer.recognizeOnceAsync(
        async (result: any) => {
          recognizer.close()
          setIsRecording(false)

          if (result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
            const recognizedText = result.text.trim()
            console.log('üìù Recognized text:', recognizedText)
            if (recognizedText) {
              setInputValue(recognizedText)
            }
          } else if (result.reason === SpeechSDK.ResultReason.NoMatch) {
            console.warn('Speech recognition: No match')
            alert('–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.')
          }
        },
        (err: any) => {
          recognizer.close()
          console.error('Speech recognition error:', err)
          setIsRecording(false)
          alert('–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.')
        }
      )
    } catch (error: any) {
      console.error('Speech recognition failed:', error)
      setIsRecording(false)
      alert(error.message || 'Speech recognition failed')
    }
  }

  const stopAzureSpeechRecognition = () => {
    if (speechRecognizerRef.current) {
      speechRecognizerRef.current.stopContinuousRecognitionAsync()
      setIsRecording(false)
    }
  }

  const handleSubmit = async (event: FormEvent) => {
    event.preventDefault()
    const trimmed = inputValue.trim()
    if (!trimmed) return

    const userMessage: ChatMessage = {
      id: `user-${Date.now()}`,
      role: 'user',
      text: trimmed
    }

    const nextConversation = [...messages, userMessage]
    setMessages(nextConversation)
    setInputValue('')
    setIsThinking(true)

    try {
      const response = await fetch('/api/dialog/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: nextConversation.map(({ role, text }) => ({ role, text })),
          language,
        }),
      })

      if (!response.ok) {
        throw new Error(`Request failed with status ${response.status}`)
      }

      const data = (await response.json()) as ChatApiResponse

      if (!data.success || !data.message) {
        throw new Error(data.error || 'Empty response from chat API')
      }

      const assistantMessage: ChatMessage = {
        id: `assistant-${Date.now()}`,
        role: 'assistant',
        text: data.message.text,
        actions: data.message.actions,
        meta: data.message.meta,
      }

      setMessages((prev) => [...prev, assistantMessage])
    } catch (error) {
      console.error('[Dialog Chat] Failed to get response:', error)
      setMessages((prev) => [
        ...prev,
        {
          id: `assistant-error-${Date.now()}`,
          role: 'assistant',
          text: tDialog.error,
        },
      ])
    } finally {
      setIsThinking(false)
    }
  }

  const handleSuggestedQuery = (query: string) => {
    setInputValue(query)
  }

  // –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Azure Speech Recognition
  const startRecording = async () => {
    if (isAvatarInitialized && azureConfig) {
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º Azure Speech Recognition
      startAzureSpeechRecognition()
    } else {
      // Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π MediaRecorder
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        const mediaRecorder = new MediaRecorder(stream)
        mediaRecorderRef.current = mediaRecorder
        audioChunksRef.current = []

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data)
          }
        }

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
          await transcribeAudio(audioBlob)
          
          // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Ç—Ä–µ–∫–∏ –º–µ–¥–∏–∞-–ø–æ—Ç–æ–∫–∞
          stream.getTracks().forEach(track => track.stop())
        }

        mediaRecorder.start()
        setIsRecording(true)
      } catch (error) {
        console.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç—É–ø–µ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É:', error)
        alert('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞.')
      }
    }
  }

  // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ
  const stopRecording = () => {
    if (speechRecognizerRef.current) {
      stopAzureSpeechRecognition()
    } else if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
    }
  }

  // –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ
  const transcribeAudio = async (audioBlob: Blob) => {
    setIsTranscribing(true)
    
    try {
      const formData = new FormData()
      formData.append('file', audioBlob, 'recording.webm')

      const response = await fetch('/api/transcribe', {
        method: 'POST',
        body: formData,
      })

      if (!response.ok) {
        throw new Error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏')
      }

      const data = await response.json()
      
      if (data.text) {
        setInputValue(data.text)
      }
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:', error)
      alert('–ù–µ —É–¥–∞–ª–æ—Å—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.')
    } finally {
      setIsTranscribing(false)
    }
  }

  // –û–∑–≤—É—á–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –±–æ—Ç–∞
  const handleTTSClick = async (messageId: string, text: string) => {
    try {
      console.log('[Dialog TTS] Clicked for message:', messageId)
      
      // –ï—Å–ª–∏ —É–∂–µ –∏–≥—Ä–∞–µ—Ç —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
      if (playingAudioId === messageId) {
        audioRef.current?.pause()
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
        if (videoRef.current) {
          videoRef.current.pause()
          videoRef.current.currentTime = 0
        }
        setPlayingAudioId(null)
        return
      }

      // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∞—É–¥–∏–æ
      if (audioRef.current) {
        audioRef.current.pause()
      }

      setLoadingAudioId(messageId)

      console.log('[Dialog TTS] Sending text to TTS:', text.substring(0, 100))

      // –ó–∞–ø—Ä–æ—Å –∫ TTS API
      const response = await fetch('/api/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          text,
          language: language === 'ru' ? 'ru-RU' : language === 'kk' ? 'kk-KZ' : 'en-US'
        }),
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('[Dialog TTS] API error:', errorText)
        throw new Error('TTS request failed')
      }

      const data = await response.json()
      console.log('[Dialog TTS] Response:', data)
      
      if (!data.audioUrl) {
        throw new Error('No audio URL in response')
      }

      // –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ
      const audio = new Audio(data.audioUrl)
      audioRef.current = audio
      
      audio.onended = () => {
        console.log('[Dialog TTS] Audio ended')
        setPlayingAudioId(null)
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –Ω–∞—á–∞–ª–æ
        if (videoRef.current) {
          videoRef.current.pause()
          videoRef.current.currentTime = 0
        }
      }
      
      audio.onerror = (e) => {
        console.error('[Dialog TTS] Audio playback error:', e)
        setPlayingAudioId(null)
        setLoadingAudioId(null)
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        if (videoRef.current) {
          videoRef.current.pause()
          videoRef.current.currentTime = 0
        }
        alert('–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ')
      }

      await audio.play()
      setPlayingAudioId(messageId)
      setLoadingAudioId(null)
      
      // –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–¥–µ–æ –æ–¥–∏–Ω —Ä–∞–∑ (–±–µ–∑ loop)
      if (videoRef.current) {
        videoRef.current.currentTime = 0
        videoRef.current.loop = false
        await videoRef.current.play()
      }

    } catch (error) {
      console.error('[Dialog TTS] Error:', error)
      setLoadingAudioId(null)
      alert('–ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ')
    }
  }

  return (
    <AuthGuard>
      <div className="flex flex-col min-h-[calc(100vh-120px)] pt-24 pb-20 px-4 sm:px-6 lg:px-8 max-w-7xl mx-auto">
        <div className="mb-8 text-center">
          <motion.h1
            initial={{ opacity: 0, y: 20 }}
            animate={{ opacity: 1, y: 0 }}
            transition={{ duration: 0.4 }}
            className="text-3xl sm:text-4xl font-semibold text-gray-900 dark:text-gray-50"
          >
            {tDialog.title}
          </motion.h1>
          <motion.p
            initial={{ opacity: 0, y: 12 }}
            animate={{ opacity: 1, y: 0 }}
            transition={{ delay: 0.1, duration: 0.4 }}
            className="mt-3 text-base sm:text-lg text-gray-600 dark:text-gray-300"
          >
            {tDialog.subtitle}
          </motion.p>
        </div>
        
        {/* Grid —Å –≤–∏–¥–µ–æ —Å–ª–µ–≤–∞ –∏ —á–∞—Ç–æ–º —Å–ø—Ä–∞–≤–∞ */}
        <div className="grid grid-cols-1 lg:grid-cols-[400px_1fr] gap-6 mb-8">
          {/* –í–∏–¥–µ–æ —Å–ª–µ–≤–∞ - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã—Å–æ—Ç–∞ */}
          <motion.div
            initial={{ opacity: 0, x: -20 }}
            animate={{ opacity: 1, x: 0 }}
            transition={{ duration: 0.4 }}
            className="bg-white dark:bg-[#1f1f1f] border border-gray-100 dark:border-[#333333] rounded-2xl p-4 shadow-sm self-start"
          >
            <div className="relative bg-gray-900 rounded-xl overflow-hidden" style={{ aspectRatio: '16/9' }}>
              <video 
                ref={videoRef}
                src="/IMG_3502.MOV"
                className="w-full h-full object-cover"
                playsInline
                muted
              />
            </div>
            
          </motion.div>

          {/* –ß–∞—Ç —Å–ø—Ä–∞–≤–∞ - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã—Å–æ—Ç–∞ —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —Å–∫—Ä–æ–ª–ª–æ–º */}
          <div className="flex flex-col h-[500px] lg:h-[600px]">
        
        {/* –û–±–ª–∞—Å—Ç—å —á–∞—Ç–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã—Å–æ—Ç–æ–π –∏ —Å–∫—Ä–æ–ª–ª–æ–º */}
        <div className="flex-1 bg-white dark:bg-[#1f1f1f] border border-gray-100 dark:border-[#333333] rounded-2xl p-4 sm:p-6 shadow-sm overflow-hidden flex flex-col">
          <div className="flex-1 overflow-y-auto space-y-4 pr-1">
            {messages.length === 0 && !isThinking && (
              <motion.div
                initial={{ opacity: 0, y: 16 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ duration: 0.3 }}
                className="bg-gray-50 dark:bg-[#2a2a2a] border border-gray-100 dark:border-[#333333] rounded-xl p-6"
              >
                <p className="text-sm text-gray-600 dark:text-gray-300 mb-4">
                  {tDialog.emptyState}
                </p>
                <div className="flex flex-wrap gap-2">
                  {suggestions.map((query) => (
                    <button
                      key={query}
                      onClick={() => handleSuggestedQuery(query)}
                      className="px-3 py-2 text-sm rounded-full bg-[#d7a13a]/10 text-[#d7a13a] hover:bg-[#d7a13a]/20 transition"
                    >
                      {query}
                    </button>
                  ))}
                </div>
              </motion.div>
            )}
            {messages.map((message) => (
              <MessageBubble 
                key={message.id} 
                message={message}
                onTTSClick={handleTTSClick}
                playingAudioId={playingAudioId}
                loadingAudioId={loadingAudioId}
              />
            ))}
            <AnimatePresence>
              {isThinking && (
                <motion.div
                  initial={{ opacity: 0 }}
                  animate={{ opacity: 1 }}
                  exit={{ opacity: 0 }}
                  className="flex gap-3 items-start"
                >
                  <AssistantAvatar />
                  <div className="bg-gray-100 dark:bg-[#2c2c2c] text-gray-500 dark:text-gray-300 px-4 py-3 rounded-2xl rounded-tl-sm text-sm">
                    ...
                  </div>
                </motion.div>
              )}
            </AnimatePresence>
            <div ref={messagesEndRef} />
          </div>
        </div>

        {/* –§–æ—Ä–º–∞ –≤–≤–æ–¥–∞ - –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∞ –≤–Ω–∏–∑—É */}
        <form onSubmit={handleSubmit} className="mt-4">
          {(isRecording || isTranscribing) && (
            <div className="mb-2 text-sm text-gray-600 dark:text-gray-300">
              {isRecording && 'üî¥ –ó–∞–ø–∏—Å—å...'}
              {isTranscribing && '‚è≥ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è...'}
            </div>
          )}
          <div className="flex flex-col sm:flex-row gap-3">
            <textarea
              value={inputValue}
              onChange={(event) => setInputValue(event.target.value)}
              placeholder={tDialog.placeholder}
              rows={2}
              disabled={isRecording || isTranscribing}
              className="flex-1 resize-none rounded-xl border border-gray-200 dark:border-[#333333] bg-white dark:bg-[#1f1f1f] px-4 py-3 text-sm text-gray-900 dark:text-gray-100 focus:outline-none focus:ring-2 focus:ring-[#d7a13a]/60 disabled:opacity-50 disabled:cursor-not-allowed"
            />
            
            {/* –ö–Ω–æ–ø–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ */}
            <button
              type="button"
              onClick={isRecording ? stopRecording : startRecording}
              disabled={isThinking || isTranscribing}
              className={cn(
                'inline-flex items-center justify-center px-4 py-3 rounded-xl text-sm font-medium transition-all',
                isRecording 
                  ? 'bg-red-500 hover:bg-red-600 text-white animate-pulse' 
                  : 'bg-gray-200 dark:bg-[#2c2c2c] hover:bg-gray-300 dark:hover:bg-[#3c3c3c] text-gray-600 dark:text-[#d7a13a]',
                (isThinking || isTranscribing) && 'opacity-60 cursor-not-allowed'
              )}
              title={isRecording ? '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å' : '–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å'}
            >
              {isTranscribing ? (
                <div className="w-5 h-5 border-2 border-[#d7a13a] border-t-transparent rounded-full animate-spin"></div>
              ) : (
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="w-5 h-5"
                  fill="none"
                  viewBox="0 0 24 24"
                  stroke="currentColor"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth={2}
                    d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
                  />
                </svg>
              )}
            </button>

            <button
              type="submit"
              disabled={!inputValue.trim() || isThinking || isRecording || isTranscribing}
              className={cn(
                'inline-flex items-center justify-center px-6 py-3 rounded-xl text-sm font-medium transition-colors',
                'bg-[#d7a13a] text-white hover:bg-[#c18c28]',
                (!inputValue.trim() || isThinking || isRecording || isTranscribing) && 'opacity-60 cursor-not-allowed'
              )}
            >
              {tDialog.send}
            </button>
          </div>
        </form>
      </div> {/* –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ –¥–ª—è —á–∞—Ç–∞ —Å–ø—Ä–∞–≤–∞ */}
      
      </div> {/* –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ –¥–ª—è grid –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ */}
      
      {/* –î—Ä—É–≥–∏–µ –∑–∞—Å–µ–¥–∞–Ω–∏—è - –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ grid */}
      <div className="mt-6">
        <h2 className="text-sm uppercase tracking-wide text-gray-400 mb-3">{tDialog.otherMeetingsTitle}</h2>
        <div className="flex flex-wrap gap-2">
          {meetings.map((meeting) => (
            <Link
              key={meeting.id}
              href={`/dialog/${meeting.code}`}
              className="px-3 py-2 text-sm rounded-full border border-gray-200 dark:border-[#333333] text-gray-600 dark:text-gray-200 hover:border-[#d7a13a] hover:text-[#d7a13a] transition"
            >
              {selectTitle(meeting, language)}
            </Link>
          ))}
        </div>
      </div>
      </div> {/* –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ flex –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ */}
    </AuthGuard>
  )
}

function MessageBubble({ message, onTTSClick, playingAudioId, loadingAudioId }: { 
  message: ChatMessage
  onTTSClick: (messageId: string, text: string) => void
  playingAudioId: string | null
  loadingAudioId: string | null
}) {
  const isUser = message.role === 'user'
  return (
    <div className={cn('flex gap-3', isUser ? 'justify-end' : 'justify-start')}>
      {!isUser && <AssistantAvatar />}
      <div className="flex flex-col items-start max-w-[85%] sm:max-w-[70%]">
        <div
          className={cn(
            'px-4 py-3 rounded-2xl text-sm shadow-sm transition',
            isUser
              ? 'bg-[#d7a13a] text-white rounded-tr-sm'
              : 'bg-gray-100 dark:bg-[#2c2c2c] text-gray-800 dark:text-gray-100 rounded-tl-sm'
          )}
        >
          <p>{message.text}</p>
          {message.actions && message.actions.length > 0 && (
            <div className="mt-3 flex flex-wrap gap-2">
              {message.actions.map((action) => (
                <Link
                  key={action.href}
                  href={action.href}
                  className="inline-flex items-center gap-2 px-3 py-1.5 text-xs font-medium rounded-full bg-white text-[#d7a13a] border border-[#d7a13a]/30 hover:bg-[#d7a13a]/10 transition"
                >
                  {action.label}
                </Link>
              ))}
            </div>
          )}
        </div>
        
        {/* –ö–Ω–æ–ø–∫–∞ –æ–∑–≤—É—á–∫–∏ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –±–æ—Ç–∞ */}
        {!isUser && (
          <button
            onClick={() => onTTSClick(message.id, message.text)}
            disabled={loadingAudioId === message.id}
            className="mt-2 flex items-center gap-2 px-3 py-1.5 text-xs text-gray-600 dark:text-gray-400 hover:text-[#d7a13a] dark:hover:text-[#d7a13a] transition-colors disabled:opacity-50 rounded-lg hover:bg-gray-100 dark:hover:bg-[#2c2c2c]"
            title={playingAudioId === message.id ? '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' : '–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ—Ç–≤–µ—Ç'}
          >
            {loadingAudioId === message.id ? (
              <>
                <svg className="w-4 h-4 animate-spin" viewBox="0 0 24 24" fill="none">
                  <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                  <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                <span>–ó–∞–≥—Ä—É–∑–∫–∞...</span>
              </>
            ) : (
              <>
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className={cn('w-4 h-4', playingAudioId === message.id && 'text-[#d7a13a]')}
                  fill="none"
                  viewBox="0 0 24 24"
                  stroke="currentColor"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth={2}
                    d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z"
                  />
                </svg>
                <span>{playingAudioId === message.id ? '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' : '–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ—Ç–≤–µ—Ç'}</span>
              </>
            )}
          </button>
        )}
      </div>
      {isUser && <UserAvatar />}
    </div>
  )
}

function selectTitle(meeting: MeetingListItem, language: Language) {
  switch (language) {
    case 'kk':
      return meeting.titleKk || meeting.titleRu || meeting.titleEn
    case 'en':
      return meeting.titleEn || meeting.titleRu || meeting.titleKk
    case 'ru':
    default:
      return meeting.titleRu || meeting.titleKk || meeting.titleEn
  }
}

function selectQuestionTitle(
  question: MeetingListItem['questions'][number],
  language: Language
) {
  switch (language) {
    case 'kk':
      return question.titleKk || question.titleRu || question.titleEn
    case 'en':
      return question.titleEn || question.titleRu || question.titleKk
    case 'ru':
    default:
      return question.titleRu || question.titleKk || question.titleEn
  }
}

function formatSuggestion(
  language: Language,
  meetingCode: string,
  questionNumber: number,
  questionTitle?: string
) {
  switch (language) {
    case 'kk':
      return `–û—Ç—ã—Ä—ã—Å—Ç—ã“£ ${meetingCode} ${questionNumber}-—Å“±—Ä–∞“ì—ã –±–æ–π—ã–Ω—à–∞ –Ω–µ —à–µ—à—ñ–ª–¥—ñ?`
    case 'en':
      return `What was decided in meeting ${meetingCode} question ${questionNumber}?`
    case 'ru':
    default:
      return questionTitle
        ? `–ß—Ç–æ —Ä–µ—à–∏–ª–∏ –Ω–∞ –∑–∞—Å–µ–¥–∞–Ω–∏–∏ ${meetingCode} –ø–æ –≤–æ–ø—Ä–æ—Å—É ${questionNumber} (${questionTitle})?`
        : `–ß—Ç–æ —Ä–µ—à–∏–ª–∏ –Ω–∞ –∑–∞—Å–µ–¥–∞–Ω–∏–∏ ${meetingCode} –ø–æ –≤–æ–ø—Ä–æ—Å—É ${questionNumber}?`
  }
}

function AssistantAvatar() {
  return (
    <div className="w-10 h-10 rounded-full bg-[#d7a13a]/15 text-[#d7a13a] flex items-center justify-center font-semibold">
      SK
    </div>
  )
}

function UserAvatar() {
  return (
    <div className="w-10 h-10 rounded-full bg-slate-200 text-slate-600 flex items-center justify-center font-semibold">
      –Ø
    </div>
  )
}
