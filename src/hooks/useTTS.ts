/**
 * React Hook for Text-to-Speech functionality
 * Supports play/pause/resume and automatic language detection
 */

import { useState, useRef, useCallback, useEffect } from 'react'
import { ttsClient } from '@/lib/tts-client'
import { prepareTextForTTS } from '@/lib/text-sanitizer'

export type TTSStatus = 'idle' | 'loading' | 'playing' | 'paused' | 'error'
export type TTSLanguage = 'kk' | 'ru' | 'en'

interface UseTTSOptions {
  language?: TTSLanguage
  autoDetectLanguage?: boolean
  onPlay?: () => void
  onPause?: () => void
  onEnd?: () => void
  onError?: (error: Error) => void
}

export function useTTS(options: UseTTSOptions = {}) {
  const {
    language, // –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —è–∑—ã–∫ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    autoDetectLanguage = false, // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª—é—á–µ–Ω–æ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —è–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞)
    onPlay,
    onPause,
    onEnd,
    onError,
  } = options

  const [status, setStatus] = useState<TTSStatus>('idle')
  const [currentText, setCurrentText] = useState<string>('')
  const [currentLang, setCurrentLang] = useState<TTSLanguage>(language || 'ru')
  
  const audioRef = useRef<HTMLAudioElement | null>(null)
  const audioUrlRef = useRef<string | null>(null)
  
  // –ö—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ URL –ø–æ —Ö–µ—à—É —Ç–µ–∫—Å—Ç–∞
  // –°—Ç—Ä—É–∫—Ç—É—Ä–∞: { textHash: { url: string, lang: string } }
  const audioCacheRef = useRef<Map<string, { url: string, lang: 'kk' | 'ru' | 'en' }>>(new Map())

  /**
   * Simple hash function for text caching
   * Uses numeric hash instead of btoa to support Unicode (Cyrillic, Kazakh, etc.)
   */
  const hashText = useCallback((text: string, lang: 'kk' | 'ru' | 'en'): string => {
    // –ü—Ä–æ—Å—Ç–æ–π —á–∏—Å–ª–µ–Ω–Ω—ã–π —Ö–µ—à –¥–ª—è Unicode-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    let hash = 0
    const sample = text.substring(0, 100) + text.substring(Math.max(0, text.length - 100))
    
    for (let i = 0; i < sample.length; i++) {
      const char = sample.charCodeAt(i)
      hash = ((hash << 5) - hash) + char
      hash = hash & hash // Convert to 32-bit integer
    }
    
    // –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —è–∑—ã–∫, –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –∏ —Ö–µ—à –≤—ã–±–æ—Ä–∫–∏
    return `${lang}-${text.length}-${Math.abs(hash).toString(36)}`
  }, [])

  /**
   * Detect language based on text content
   */
  const detectLanguage = useCallback((text: string): 'kk' | 'ru' | 'en' => {
    // –ö–∞–∑–∞—Ö—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã: ”ô, “ì, “õ, “£, ”©, “±, “Ø, “ª, —ñ
    const kazakhChars = /[”ô“ì“õ“£”©“±“Ø“ª—ñ]/i
    const hasKazakhChars = kazakhChars.test(text)
    
    if (hasKazakhChars) return 'kk'
    
    // –ö–∏—Ä–∏–ª–ª–∏—Ü–∞ (—Ä—É—Å—Å–∫–∏–π)
    const cyrillicChars = /[–∞-—è–ê-–Ø—ë–Å]/
    const hasCyrillicChars = cyrillicChars.test(text)
    
    // –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ - —Ä—É—Å—Å–∫–∏–π, –∏–Ω–∞—á–µ - –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
    return hasCyrillicChars ? 'ru' : 'en'
  }, [])

  /**
   * Get effective language based on priority:
   * 1. Explicitly passed lang parameter
   * 2. Language from hook options (interface language)
   * 3. Auto-detected language (if enabled)
   * 4. Default 'ru'
   * 
   * Note: TTS API supports 'kk', 'ru', and 'en'
   */
  const getEffectiveLanguage = useCallback((text: string, explicitLang?: TTSLanguage): 'kk' | 'ru' | 'en' => {
    // Priority 1: Explicit parameter
    if (explicitLang) {
      if (explicitLang === 'kk') return 'kk'
      if (explicitLang === 'ru') return 'ru'
      if (explicitLang === 'en') return 'en'
    }
    
    // Priority 2: Language from options (interface language)
    if (language) {
      if (language === 'kk') return 'kk'
      if (language === 'ru') return 'ru'
      if (language === 'en') return 'en'
    }
    
    // Priority 3: Auto-detect
    if (autoDetectLanguage) {
      return detectLanguage(text)
    }
    
    // Priority 4: Default
    return 'ru'
  }, [language, autoDetectLanguage, detectLanguage])

  /**
   * Generate and play audio (with caching)
   */
  const generateAndPlay = useCallback(async (text: string, lang?: TTSLanguage) => {
    console.log('[useTTS] ==================== GENERATE AND PLAY START ====================')
    try {
      console.log('[useTTS] üé¨ Starting audio generation')
      console.log('[useTTS] üìä Input params:', {
        textLength: text.length,
        explicitLang: lang,
        interfaceLang: language,
        autoDetect: autoDetectLanguage,
      })
      
      setStatus('loading')
      console.log('[useTTS] üìä Status set to: loading')
      
      // –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç Markdown —Ä–∞–∑–º–µ—Ç–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
      const cleanedText = prepareTextForTTS(text, 5000) // –ú–∞–∫—Å–∏–º—É–º 5000 —Å–∏–º–≤–æ–ª–æ–≤
      
      console.log('[useTTS] üßπ Text cleaning:')
      console.log('  - Original length:', text.length)
      console.log('  - Cleaned length:', cleanedText.length)
      console.log('  - Preview:', cleanedText.substring(0, 150))
      
      // Get effective language based on priority
      const effectiveLanguage = getEffectiveLanguage(text, lang)
      setCurrentLang(effectiveLanguage)
      setCurrentText(cleanedText) // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
      
      console.log('[useTTS] üåê Language detection:')
      console.log('  - Effective language:', effectiveLanguage)
      console.log('  - Source:', lang ? 'explicit parameter' : language ? 'interface setting' : autoDetectLanguage ? 'auto-detected' : 'default fallback')

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
      const textHash = hashText(cleanedText, effectiveLanguage)
      const cached = audioCacheRef.current.get(textHash)
      
      console.log('[useTTS] üíæ Cache check:')
      console.log('  - Text hash:', textHash)
      console.log('  - Cache hit:', !!cached)
      console.log('  - Total cache size:', audioCacheRef.current.size)
      
      let audioUrl: string
      
      if (cached) {
        console.log('[useTTS] ‚úÖ Using cached audio')
        console.log('  - URL type:', cached.url.startsWith('blob:') ? 'Blob URL' : cached.url.startsWith('data:') ? 'Data URI' : 'Unknown')
        console.log('  - Cached language:', cached.lang)
        audioUrl = cached.url
      } else {
        console.log('[useTTS] üé§ Generating NEW audio via TTS API')
        console.log('  - Text sample:', cleanedText.substring(0, 100))
        console.log('  - Language:', effectiveLanguage)

        try {
          // Generate audio URL with cleaned text
          audioUrl = await ttsClient.generateSpeechURL(cleanedText, effectiveLanguage)
          
          console.log('[useTTS] ‚úÖ Audio generated successfully')
          console.log('  - URL type:', audioUrl.startsWith('blob:') ? 'Blob URL' : audioUrl.startsWith('data:') ? 'Data URI' : 'Unknown')
          console.log('  - URL length:', audioUrl.length)
          
          // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
          audioCacheRef.current.set(textHash, { url: audioUrl, lang: effectiveLanguage })
          console.log('[useTTS] üíæ Audio cached')
          console.log('  - Hash:', textHash)
          console.log('  - New cache size:', audioCacheRef.current.size)
        } catch (genError) {
          console.error('[useTTS] ‚ùå Audio generation FAILED')
          console.error('  - Error:', genError)
          throw genError
        }
      }
      
      audioUrlRef.current = audioUrl

      console.log('[useTTS] üéµ Creating Audio element')
      console.log('  - URL:', audioUrl.substring(0, 100))
      
      // Create audio element
      const audio = new Audio(audioUrl)
      audioRef.current = audio
      
      console.log('[useTTS] ‚úÖ Audio element created')
      console.log('  - Can play:', audio.canPlayType('audio/mpeg'))
      console.log('  - Ready state:', audio.readyState)

      // Set up event listeners
      audio.onloadedmetadata = () => {
        console.log('[useTTS] üìä Audio metadata loaded')
        console.log('  - Duration:', audio.duration, 'seconds')
        console.log('  - Ready state:', audio.readyState)
      }

      audio.oncanplay = () => {
        console.log('[useTTS] ‚úÖ Audio can play (enough data loaded)')
      }

      audio.onplay = () => {
        setStatus('playing')
        onPlay?.()
        console.log('[useTTS] ‚ñ∂Ô∏è Audio playing')
        console.log('  - Current time:', audio.currentTime)
        console.log('  - Duration:', audio.duration)
      }

      audio.onpause = () => {
        // Only set paused if not ended
        if (!audio.ended) {
          setStatus('paused')
          onPause?.()
          console.log('[useTTS] ‚è∏Ô∏è Audio paused')
          console.log('  - Current time:', audio.currentTime)
        }
      }

      audio.onended = () => {
        setStatus('idle')
        onEnd?.()
        cleanup()
        console.log('[useTTS] ‚úÖ Audio ended naturally')
      }

      audio.onerror = (e) => {
        const error = new Error('Audio playback error')
        setStatus('error')
        onError?.(error)
        console.error('[useTTS] ‚ùå Audio playback ERROR')
        console.error('  - Error event:', e)
        console.error('  - Error code:', audio.error?.code)
        console.error('  - Error message:', audio.error?.message)
        console.error('  - Audio src:', audio.src?.substring(0, 100))
        console.error('  - Ready state:', audio.readyState)
        console.error('  - Network state:', audio.networkState)
        cleanup()
      }

      console.log('[useTTS] üé¨ Starting audio playback')
      // Start playing
      await audio.play()
      console.log('[useTTS] ‚úÖ audio.play() resolved successfully')
      console.log('[useTTS] ==================== GENERATE AND PLAY END ====================')

      
    } catch (error) {
      console.error('[useTTS] ==================== ERROR OCCURRED ====================')
      console.error('[useTTS] ‚ùå Generation/Playback error')
      console.error('  - Error type:', error?.constructor?.name)
      console.error('  - Error message:', error instanceof Error ? error.message : String(error))
      console.error('  - Error stack:', error instanceof Error ? error.stack : 'N/A')
      console.error('  - Current status:', status)
      console.error('[useTTS] ============================================================')
      
      setStatus('error')
      onError?.(error as Error)
      cleanup()
    }
  }, [getEffectiveLanguage, hashText, language, autoDetectLanguage, onPlay, onPause, onEnd, onError, status])

  /**
   * Play audio (generate new or resume paused)
   */
  const play = useCallback(async (text?: string, lang?: TTSLanguage) => {
    console.log('[useTTS] üé¨ Play called:', { 
      status, 
      hasText: !!text, 
      hasAudio: !!audioRef.current,
      currentText: currentText.substring(0, 50)
    })
    
    if (status === 'paused' && audioRef.current) {
      // Resume paused audio
      console.log('[useTTS] ‚ñ∂Ô∏è Resuming paused audio (not generating new)')
      await audioRef.current.play()
    } else if (text) {
      // Generate and play new audio
      console.log('[useTTS] üé§ Generating new audio')
      await generateAndPlay(text, lang)
    } else {
      console.warn('[useTTS] ‚ö†Ô∏è Play called without text and not paused')
    }
  }, [status, currentText, generateAndPlay])

  /**
   * Pause audio
   */
  const pause = useCallback(() => {
    if (audioRef.current && !audioRef.current.paused) {
      console.log('[useTTS] ‚è∏Ô∏è Pausing audio (currentTime:', audioRef.current.currentTime, ')')
      audioRef.current.pause()
    } else {
      console.warn('[useTTS] ‚ö†Ô∏è Cannot pause: no audio or already paused')
    }
  }, [])

  /**
   * Stop audio and reset
   */
  const stop = useCallback(() => {
    if (audioRef.current) {
      console.log('[useTTS] ‚èπÔ∏è Stopping audio')
      audioRef.current.pause()
      audioRef.current.currentTime = 0
    }
    cleanup()
    setStatus('idle')
  }, [])

  /**
   * Toggle play/pause
   */
  const toggle = useCallback(async (text?: string, lang?: TTSLanguage) => {
    const audioPaused = audioRef.current?.paused ?? true
    const audioEnded = audioRef.current?.ended ?? true
    
    console.log('[useTTS] üîÄ Toggle called:', { 
      status, 
      hasText: !!text, 
      hasAudio: !!audioRef.current,
      audioPaused,
      audioEnded,
      currentText: currentText.substring(0, 50) 
    })
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ audio —ç–ª–µ–º–µ–Ω—Ç–∞, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ status
    if (audioRef.current && !audioPaused && !audioEnded) {
      // Audio —ç–ª–µ–º–µ–Ω—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–≥—Ä–∞–µ—Ç -> –ø–∞—É–∑–∞
      console.log('[useTTS] ‚è∏Ô∏è Toggle: Pausing (audio is playing)')
      pause()
    } else if (audioRef.current && audioPaused && !audioEnded) {
      // Audio —ç–ª–µ–º–µ–Ω—Ç –Ω–∞ –ø–∞—É–∑–µ -> –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
      console.log('[useTTS] ‚ñ∂Ô∏è Toggle: Resuming from pause (audio is paused)')
      await play() // Don't pass text, just resume
    } else if (text) {
      // –ù–µ—Ç audio —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–ª–∏ –æ–Ω –∑–∞–∫–æ–Ω—á–∏–ª—Å—è -> –Ω–æ–≤–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
      console.log('[useTTS] üé¨ Toggle: Starting new audio (no audio or ended)')
      await play(text, lang)
    }
  }, [status, currentText, play, pause])

  /**
   * Cleanup audio resources
   */
  const cleanup = useCallback(() => {
    if (audioRef.current) {
      audioRef.current.onplay = null
      audioRef.current.onpause = null
      audioRef.current.onended = null
      audioRef.current.onerror = null
      audioRef.current = null
    }
    if (audioUrlRef.current) {
      // Note: –Ω–µ —É–¥–∞–ª—è–µ–º URL –∏–∑ –∫—ç—à–∞, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Å–Ω–æ–≤–∞
      audioUrlRef.current = null
    }
  }, [])

  /**
   * Cleanup all cached audio on unmount
   */
  const cleanupCache = useCallback(() => {
    console.log('[useTTS] üßπ Cleaning up cache, size:', audioCacheRef.current.size)
    audioCacheRef.current.forEach(({ url }) => {
      URL.revokeObjectURL(url)
    })
    audioCacheRef.current.clear()
  }, [])

  /**
   * Play audio from preloaded URL (no generation needed)
   */
  const playFromUrl = useCallback(async (audioUrl: string, text: string) => {
    try {
      console.log('[useTTS] üéµ Playing from preloaded URL')
      setStatus('loading')
      setCurrentText(text)
      
      // Create audio element from preloaded URL
      const audio = new Audio(audioUrl)
      audioRef.current = audio
      audioUrlRef.current = audioUrl

      // Set up event listeners
      audio.onplay = () => {
        setStatus('playing')
        onPlay?.()
        console.log('[useTTS] ‚ñ∂Ô∏è Preloaded audio playing')
      }

      audio.onpause = () => {
        if (!audio.ended) {
          setStatus('paused')
          onPause?.()
          console.log('[useTTS] ‚è∏Ô∏è Preloaded audio paused')
        }
      }

      audio.onended = () => {
        setStatus('idle')
        onEnd?.()
        // Don't cleanup - URL might be reused
        console.log('[useTTS] ‚úÖ Preloaded audio ended')
      }

      audio.onerror = (e) => {
        const error = new Error('Audio playback error')
        setStatus('error')
        onError?.(error)
        console.error('[useTTS] ‚ùå Preloaded audio error:', e)
      }

      // Start playing
      await audio.play()
      
    } catch (error) {
      console.error('[useTTS] ‚ùå Playback error:', error)
      setStatus('error')
      onError?.(error as Error)
    }
  }, [onPlay, onPause, onEnd, onError])

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      cleanup()
      cleanupCache()
    }
  }, [cleanup, cleanupCache])

  return {
    status,
    currentText,
    currentLang,
    isPlaying: status === 'playing',
    isPaused: status === 'paused',
    isLoading: status === 'loading',
    isError: status === 'error',
    play,
    pause,
    stop,
    toggle,
    playFromUrl, // NEW: Play from preloaded URL
  }
}
